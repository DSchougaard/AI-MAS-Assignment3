\def\year{2015}
%File: formatting-instruction.tex
\documentclass[letterpaper]{article}

% Required Packages
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

% Section numbers. 
\setcounter{secnumdepth}{2}  

\nocopyright
\begin{document}
% Title and author information
\title{How to Kill a Hamster - Group NULL\\ 02285 AI \& MAS}
\author{Daniel Schougaard \\ \textit{s103446} \And Kasper Reindahl Rasmussen\\ \textit{s103476} \And Martin V. Ottesen\\ \textit{s060186}}
\maketitle

\begin{abstract}
The abstract goes here. Please read this document carefully before preparing your manuscript.

To ensure that all reports have a uniform appearance corresponding to published papers at the major AI conferences (like IJCAI and AAAI), authors must adhere to the following instructions. 
\end{abstract}

\section{Introduction}
	Martin
	Like so ~\cite{book2015}. 
\section{Background}
	Martin\\
	Theory : Relaxation

\section{Related Work}
	Martin

\section{Methods}
	\subsection{Brief Overview of Design and Implementation}
		Reindahl\\
		the general structure is a multi body approach with preprocessing of goals.
		
		the preprocessing consist of clustering the goals to the agent.
			Randomization
		
		we assume that goals located near each 
		goal decomposition 
			subgoal independence
			adding goals for agents
		
				
	\subsection{Search}
		\subsubsection{The Heuristic}
			Reindahl \\
			RELAXATION OF A RABBIT


	\subsection{Conflict Resolution}
		Since we're using multiple agents, each planning their own route, conflicts are bound to happen. We've chosen to rely on a method to resolve these, somewhat similar to online planning. But first and foremost, we need to describe exactly how we \emph{detect} these conflicts.

		\subsubsection{Detecting the Conflicts}
			Currently we rely on three different methods for detecting conflicts. The first method is simply letting the server \emph{tell} the client, that there is a conflict. This is by far the simplest possible way to detect a conflict, but it does inevitably result in a grater overhead. 

			The second approach is, that we employ a sort of double search. By first relaxing the domain, into something we call a subdomain, only containing the agent itself, and boxes it can move, we then search this domain. Using the length of the found route, we get a threshold, for determining whether or not the normal search is stuck.


			%First we relax the domain, removing all other agents and boxes, that the current agent can not move. This results in a new subdomain, in which a search is performed. This results in a sort of threshold: In a perfect world, a solution for this problem exists in $X$ moves. This is then again used, to cut off the normal search, once it has taken too long. When this happens, we assume that it is because of a conflict. Using the route of the relaxed search, we identify which objects are in the way, causing this conflict.

			The third an final approach is using something we call a \verb=History=. Due to the way we implemented searching and re-planning, occasionally two agents could find themselves in a situation, where both of them would \textsc{cycle} between two locations. The \verb=History= is memory of a certain length, containing information about where an agent has been for the past $x$ moves. Should more than a certain fraction of this history be of the same location, a cycle is detected.

		\subsubsection{Types of Conflicts}
			Having detected a conflict, we partition the causes into one of two groups: The cases where it is only a box in the way, and the cases where it is a box. As a rule, all boxes found in the route, is handled first. This is done to avoid cases, where an agent otherwise asked to move a box, is told to get out of the way. An example of this, can be seen below. $0$ is a \verb=BLUE= agent, and $1$ is a \verb=RED= agent. The box $B$ is also \verb=RED=. 
			\begin{verbatim}
				...+++++++++...
				     0 B1
				...+++++++++...
			\end{verbatim}
			In this example, $0$ would like to move right. Obviously, that is impossible, due to the fact that both the agent $1$ and the box $B$ is in the way. Should we chose to handle agents first, $1$ would move out of the way, leaving no one to move the box $1$.

		\subsubsection{Resolving a Box Conflict}
			To move a box out of the way, we first need to identify which agent should ``help". This is done by first trying to find the nearest agent, which currently does not have a plan. If none is found, the nearest agent is simply hijacked. Once the selected agent has reached the box, we employ a very naïve search: We breadth-first search, until both agent and box is out of the route.

		\subsubsection{Resolving an Agent Conflict}
			If it should happen that is an agent that is in the route, this agent is told to get out of the way, \emph{unless} it's plans length, is below a certain threshold. Should the plan be below this threshold, the agent in the way is allowed to finish its current plan, before getting out of the way \emph{(if it is required at that time)}.

		\subsubsection{Resolving a Cycle}
			A cycle is resolved by simply injecting NoOps in one of the agents, enabling the other to re-plan itself out of the problem area.
		

\section{Experiments and Results}
	Throughout the development and implementation of the client for this project, we have tested out various ideas and designs. This sections contains a mix of experiments performed during all stages of development.

	\subsection{Distance Maps}
		During the early stages of development, we quickly realized that have a sort of modular approach to calculating distances would be beneficial. First few iterations we only employed a Manhattan distance calculation. Later on we then implemented various approaches to generating what we call "Real Distance Maps": They calculate the \emph{actual} distance, between to coordinate sets, by pre-processing.

		All testing is done on single agent levels, since we're testing the efficiency of using the real distance map, instead of a Manhattan distance. To create a fixed point of reference, a greedy approach is used on all benchmarks.
		\begin{tabular}{ | l | l | l | }
			\hline
			\textbf{Level} 	& \textbf{Manhattan} 	& \textbf{Floyd–Warshall} \\
			\hline
			SABispebjerg 	& - 					& - \\
			SAGroup42F13 	& - 					& - \\
			SACrunch 		& - 					& - \\
			SAboxesOfHanoi 	& - 					& - \\
			\hline
		\end{tabular}
		As it is seen, the real distance map, significantly increases the performance of our search client on the test cases, as we suspected.

	\subsection{Comparison of Approaches}
		Daniel
		% Greedy vs AStar

	\subsection{Goals}
		Kasper
		\begin{itemize}
			\item{Individual goals vs series of goals}
			\item{Prioritizing goals}
		\end{itemize}


\section{Discussion}
	\subsection{Comparison of Levels}
	\begin{itemize}
		\item{Why is this?}
		\item{Large levels!}
		\item{Coordination amongst Agents.}
	\end{itemize}


\section{Future Work}
	\begin{itemize}
		\item{Large Levels}
		\item{Coordination}
	\end{itemize}

\section{References}
	Martin\\
	6 references, 3 papers.
		
		
% References and end of paper
\bibliographystyle{aaai}
\bibliography{bibliography}
\end{document}